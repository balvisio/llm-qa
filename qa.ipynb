{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/bruno/.local/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "INDEX_NAME = \"trainual.index\"\n",
    "STORE_NAME = \"trainual.pkl\"\n",
    "\n",
    "# To Download LLAMA: https://github.com/facebookresearch/llama/issues/374#issuecomment-1643228958\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "#     max_length=3773,\n",
    "#     temperature=0,\n",
    "#     top_p=0.95,\n",
    "#     repetition_penalty=1.15,\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# Load the LangChain.\n",
    "index = faiss.read_index(INDEX_NAME)\n",
    "\n",
    "with open(STORE_NAME, \"rb\") as f:\n",
    "    store = pickle.load(f)\n",
    "\n",
    "store.index = index\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=local_llm, retriever=store.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the steps to add PTO to Clarizen?\n",
      "Answer:  The steps to add PTO to Clarizen are as follows:\n",
      "\n",
      "1. Login to Clarizen\n",
      "2. Look for your username at the top right corner\n",
      "3. Pull down on your username and look for “My Details” link\n",
      "4. Now you have to extend the details page by clicking on the “More info” link in the middle of the page\n",
      "5. Look for the section called “Personal Details” and click on the edit link under Calendar\n",
      "6. Add an exception for all the hours/days you are on PTO (the “Name” is any description, like “Vacation”)\n",
      "\n",
      "The steps are important because they help Clarizen block out your PTO hours and adjust your resource load, tasks, and other data reporting things that BioTeam uses to run reports and charts.\n",
      "Sources: \n"
     ]
    }
   ],
   "source": [
    "input_ = input()\n",
    "print(f\"Question: {input_}\")\n",
    "result = chain({\"question\": input_})\n",
    "print(f\"Answer: {result['answer']}\")\n",
    "print(f\"Sources: {result['sources']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-qa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
